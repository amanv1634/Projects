{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5gqX8u61u6Bi",
    "outputId": "0fbffda6-9097-4660-8de3-25dfee1ba470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "chmod 777 /tmp\n",
    "mkdir data\n",
    "apt-get update --allow-unauthenticated \n",
    "apt-get update -y --fix-missing \n",
    "pip install selenium\n",
    "apt-get install chromium-chromedriver -y --fix-missing\n",
    "pip install joblib\n",
    "apt-get update --fix-missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnuAsPXxu6Bo"
   },
   "outputs": [],
   "source": [
    "# ! ls /usr/bin # Webdriver and Chromium binary installed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "YvhxF33iu6Bq",
    "outputId": "ebb375b4-f43f-4993-ee57-5c0e726f2d8e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IP Address</th>\n",
       "      <th>Port</th>\n",
       "      <th>Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Anonymity</th>\n",
       "      <th>Google</th>\n",
       "      <th>Https</th>\n",
       "      <th>Last Checked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>41.75.4.208</td>\n",
       "      <td>53281</td>\n",
       "      <td>BW</td>\n",
       "      <td>Botswana</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>21 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200.236.221.242</td>\n",
       "      <td>33054</td>\n",
       "      <td>BR</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 minute ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>36.37.139.2</td>\n",
       "      <td>43997</td>\n",
       "      <td>KH</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>4 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>124.41.243.22</td>\n",
       "      <td>47894</td>\n",
       "      <td>NP</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>21 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>195.138.82.198</td>\n",
       "      <td>40301</td>\n",
       "      <td>UA</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>21 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>185.156.35.156</td>\n",
       "      <td>46579</td>\n",
       "      <td>PL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>20 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.106.114.134</td>\n",
       "      <td>8080</td>\n",
       "      <td>ID</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 minute ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>87.197.156.62</td>\n",
       "      <td>23500</td>\n",
       "      <td>SK</td>\n",
       "      <td>Slovakia</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 minute ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>169.255.126.211</td>\n",
       "      <td>30640</td>\n",
       "      <td>NG</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 minute ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>125.27.251.24</td>\n",
       "      <td>36048</td>\n",
       "      <td>TH</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2 minutes ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IP Address   Port Code    Country    Anonymity Google Https  \\\n",
       "286      41.75.4.208  53281   BW   Botswana  elite proxy     no   yes   \n",
       "6    200.236.221.242  33054   BR     Brazil  elite proxy     no   yes   \n",
       "78       36.37.139.2  43997   KH   Cambodia  elite proxy     no   yes   \n",
       "278    124.41.243.22  47894   NP      Nepal  elite proxy     no   yes   \n",
       "276   195.138.82.198  40301   UA    Ukraine  elite proxy     no   yes   \n",
       "250   185.156.35.156  46579   PL     Poland  elite proxy     no   yes   \n",
       "2    103.106.114.134   8080   ID  Indonesia  elite proxy     no   yes   \n",
       "8      87.197.156.62  23500   SK   Slovakia  elite proxy     no   yes   \n",
       "17   169.255.126.211  30640   NG    Nigeria  elite proxy     no   yes   \n",
       "50     125.27.251.24  36048   TH   Thailand  elite proxy     no   yes   \n",
       "\n",
       "       Last Checked  \n",
       "286  21 minutes ago  \n",
       "6      1 minute ago  \n",
       "78    4 minutes ago  \n",
       "278  21 minutes ago  \n",
       "276  21 minutes ago  \n",
       "250  20 minutes ago  \n",
       "2      1 minute ago  \n",
       "8      1 minute ago  \n",
       "17     1 minute ago  \n",
       "50    2 minutes ago  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import list of https proxies\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
    "URL = \"https://free-proxy-list.net/\"\n",
    "req = requests.get(URL, headers = headers) # .json()\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "for body in soup(\"tbody\"):\n",
    "    body.unwrap()\n",
    "\n",
    "df = pd.read_html(str(soup), flavor=\"bs4\")\n",
    "df = pd.DataFrame(df[0])\n",
    "proxies = df[(df.Https == 'yes')] # (df.Https == 'yes') & (df.Country == 'United States')\n",
    "proxies['Port'] = proxies['Port'].astype(int)\n",
    "proxies.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YbmG4cNLu6Bu",
    "outputId": "3152f764-355e-490b-afe9-582b6832dc32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your IP  {\"ip\":\"73.142.126.75\"}\n"
     ]
    }
   ],
   "source": [
    "# ## Your IP address\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = 'https://api.ipify.org?format=json'\n",
    "req = requests.get(URL) # .json()\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "ip = soup.find('p').text\n",
    "print('Your IP ', ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K55eNn2zu6Bx",
    "outputId": "df75aa65-0415-41bf-fdf0-20b19adea981"
   },
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'Anaconda3\bin' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mcmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_line_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             self.process = subprocess.Popen(cmd, env=self.env,\n\u001b[0m\u001b[0;32m     73\u001b[0m                                             \u001b[0mclose_fds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplatform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'Windows'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1308\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-030991545900>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\ProgramData\\Anaconda3\\bin'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C:\\ProgramData\\Anaconda3\\bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m#driver.get(\"https://api.ipify.org/?format=json\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://www.opentable.com/boston-restaurant-listings\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mservice_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             log_path=service_log_path)\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 raise WebDriverException(\n\u001b[0m\u001b[0;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[0;32m     83\u001b[0m                         os.path.basename(self.path), self.start_error_message)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: 'Anaconda3\bin' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
     ]
    }
   ],
   "source": [
    "## Test Headless Browser with BeautifulSoup\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.binary_location = 'C:\\ProgramData\\Anaconda3\\bin'\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='C:\\ProgramData\\Anaconda3\\bin', options = options)\n",
    "#driver.get(\"https://api.ipify.org/?format=json\")\n",
    "driver.get(\"http://www.opentable.com/boston-restaurant-listings\")\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html)\n",
    "#finding restaurant names\n",
    "#this will create a list of html tags that match this criteria but it gives the results of only one page\n",
    "for restaurant in soup.find_all(name='span', attrs={'class':'rest-row-name-text'}):\n",
    "    print(restaurant.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qviSDl6XVHOQ"
   },
   "outputs": [],
   "source": [
    "#finding restaurant locations\n",
    "for restaurant in soup.find_all(name='span', attrs={'class=\"rest-row-meta--location rest-row-meta-text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PzMiplX2u6B0",
    "outputId": "15324dd2-ada4-4407-8cf8-bbdc2e78f6e6"
   },
   "outputs": [],
   "source": [
    "## Unrendered proxy return without headless\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
    "URL = 'https://api.ipify.org?format=json'\n",
    "proxy = {'https': '200.255.122.174:8080'}\n",
    "req = requests.get(URL, proxies = proxy, headers = headers) # .json()\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "ip = soup.find('p').text\n",
    "print('IP from scrape w/proxy ', ip)\n",
    "\n",
    "# Output\n",
    "# IP from scrape w/proxy  {\"ip\":\"200.255.122.174\"} # Tests proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "colab_type": "code",
    "id": "UzqNQbmDu6B3",
    "outputId": "4d957db8-91a9-460a-bca2-ff87a652eaf8"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Headless Scrape w/Single Proxy\n",
    "### Imports list of https proxies and renders a sample in Chromium\n",
    "\n",
    "## Import list of https proxies\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def proxySelenium(proxyIP, proxyPort, headless = True):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        ourProxy = str(proxyIP) + \":\" + str(proxyPort) # Use this for https anonymous/elite \n",
    "\n",
    "        proxy = Proxy({\n",
    "            'proxyType': ProxyType.MANUAL,\n",
    "            'httpProxy': ourProxy,\n",
    "            'ftpProxy' : ourProxy,\n",
    "            'sslProxy' : ourProxy,\n",
    "            'noProxy'  : ''\n",
    "        })\n",
    "\n",
    "        options = webdriver.ChromeOptions()\n",
    "        if headless == True:\n",
    "          \n",
    "          # Deletes web preview if it exists already\n",
    "          if os.path.exists('data/' + str(proxyIP) + '_' + 'screenshot.png'):\n",
    "            os.remove('data/' + str(proxyIP) + '_' + 'screenshot.png')\n",
    "            \n",
    "          options.add_argument('--headless')\n",
    "          options.add_argument('--no-sandbox')\n",
    "          options.add_argument('--disable-dev-shm-usage')\n",
    "          options.binary_location = '/usr/bin/chromium-browser'\n",
    "\n",
    "        # Configure capabilities \n",
    "        capabilities = dict(DesiredCapabilities.CHROME)\n",
    "        proxy.add_to_capabilities(capabilities)\n",
    "\n",
    "        driver = webdriver.Chrome(executable_path='/usr/bin/chromedriver', desired_capabilities = capabilities, options = options)\n",
    "        driver.set_page_load_timeout(200)\n",
    "\n",
    "        # Open page and take screenshot\n",
    "        driver.get(\"http://www.ipify.org/\")\n",
    "\n",
    "        if headless == False:\n",
    "            time.sleep(3)\n",
    "\n",
    "        driver.get_screenshot_as_file('data/' + str(proxyIP) + '_' + 'screenshot.png')\n",
    "\n",
    "      # IP Text\n",
    "        driver.get(\"https://api.ipify.org/?format=json\")\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "        ip = soup.find('pre').text\n",
    "        driver.quit()\n",
    "\n",
    "        if headless == True:\n",
    "          ## Show Screeenshot\n",
    "          image = mpimg.imread('data/' + str(proxyIP) + '_' + 'screenshot.png')\n",
    "          plt.figure(figsize=(20,20))\n",
    "          plt.imshow(image)\n",
    "          plt.show()\n",
    "            \n",
    "          # Remove Image\n",
    "          os.remove('data/' + str(proxyIP) + '_' + 'screenshot.png')\n",
    "\n",
    "        print(\"Working: \" + str(proxyIP) + \":\" + str(proxyPort))\n",
    "        return \"Working: \" + str(proxyIP) + \":\" + str(proxyPort)\n",
    "      \n",
    "    except:\n",
    "        print(\"Proxy inactive: \" + str(proxyIP) + \":\" + str(proxyPort))\n",
    "        return \"Proxy inactive: \" + str(proxyIP) + \":\" + str(proxyPort)\n",
    "        driver.quit()\n",
    "    \n",
    "# prox = proxies.sample(n=1)\n",
    "proxyIP = '200.255.122.174'     # list(prox['IP Address'])[0] # \n",
    "proxyPort = '8080'              # list(prox['Port'])[0] \n",
    "\n",
    "print('IP to test: ', proxyIP, ' and Port:', proxyPort)\n",
    "proxySelenium(proxyIP, proxyPort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "colab_type": "code",
    "id": "VkhZZqKAu6B7",
    "outputId": "56a0a0e2-9098-42d2-f232-3a6eb77084c0"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Parallelized proxy check over 10 sampled IPs w/Non-Headless\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def soupParallel(proxyIP, proxyPort):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        time.sleep(1)\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
    "        URL = 'https://api.ipify.org?format=json'\n",
    "        proxy = {'https': str(proxyIP) + \":\" + str(proxyPort)}\n",
    "        print(\"Input IP proxy: \", proxy)\n",
    "        req = requests.get(URL, proxies = proxy, headers = headers) # .json()\n",
    "        soup = BeautifulSoup(req.text, \"lxml\")\n",
    "        ip = soup.find('p').text\n",
    "        return 'IP from scrape w/proxy ' + str(ip)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print(\"Proxy inactive: \" + str(proxy))\n",
    "        return \"Proxy inactive: \" + str(proxy)\n",
    "        \n",
    "## Parallel read of soupParallel function\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import multiprocessing\n",
    "\n",
    "with parallel_backend('multiprocessing'):\n",
    "\n",
    "  num_cores = multiprocessing.cpu_count()\n",
    "  results = Parallel(n_jobs = num_cores)(delayed(soupParallel)(proxyIP = list(proxies['IP Address'])[i], \n",
    "        proxyPort = list(proxies['Port'])[i]) for i in range(0, len(proxies.head(10)) )) # len(proxies.head(10))\n",
    "\n",
    "print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "v3_mWhrIu6B-",
    "outputId": "d9a20e54-e608-43a6-fc87-fa010005c49a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Headless Scrape w/Single Proxy\n",
    "### Imports list of https proxies and renders a sample in Chromium\n",
    "\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def proxySeleniumParallel(proxyIP, proxyPort, headless = True):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        ourProxy = str(proxyIP) + \":\" + str(proxyPort) # Use this for https anonymous/elite \n",
    "\n",
    "        proxy = Proxy({\n",
    "            'proxyType': ProxyType.MANUAL,\n",
    "            'httpProxy': ourProxy,\n",
    "            'ftpProxy' : ourProxy,\n",
    "            'sslProxy' : ourProxy,\n",
    "            'noProxy'  : ''\n",
    "        })\n",
    "\n",
    "        options = webdriver.ChromeOptions()\n",
    "        if headless == True:\n",
    "          \n",
    "          # Deletes web preview if it exists already\n",
    "          if os.path.exists('data/' + str(proxyIP) + '_' + 'screenshot.png'):\n",
    "            os.remove('data/' + str(proxyIP) + '_' + 'screenshot.png')\n",
    "            \n",
    "          options.add_argument('--headless')\n",
    "          options.add_argument('--no-sandbox')\n",
    "          options.add_argument('--disable-dev-shm-usage')\n",
    "          options.binary_location = '/usr/bin/chromium-browser'\n",
    "\n",
    "        # Configure capabilities \n",
    "        capabilities = dict(DesiredCapabilities.CHROME)\n",
    "        proxy.add_to_capabilities(capabilities)\n",
    "\n",
    "        driver = webdriver.Chrome(executable_path='/usr/bin/chromedriver', desired_capabilities = capabilities, options = options)\n",
    "        driver.set_page_load_timeout(200)\n",
    "\n",
    "        # Open page and take screenshot\n",
    "        driver.get(\"https://www.whatismyip.com/ip-address-lookup/\") # http://www.ipify.org/\n",
    "\n",
    "        if headless == False:\n",
    "            time.sleep(3)\n",
    "\n",
    "        driver.get_screenshot_as_file('data/' + str(proxyIP) + '_' + 'screenshot.png')\n",
    "\n",
    "      # IP Text\n",
    "        driver.get(\"https://api.ipify.org/?format=json\")\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "        ip = soup.find('pre').text\n",
    "        driver.quit()\n",
    "\n",
    "        if headless == True:\n",
    "          ## Show Screeenshot\n",
    "          image = mpimg.imread('data/' + str(proxyIP) + '_' + 'screenshot.png')\n",
    "          plt.figure(figsize=(20,30))\n",
    "          plt.imshow(image)\n",
    "          plt.show()\n",
    "            \n",
    "          # Remove Image\n",
    "          os.remove('data/' + str(proxyIP) + '_' + 'screenshot.png')\n",
    "\n",
    "        print(\"Working: \" + str(proxyIP) + \":\" + str(proxyPort))\n",
    "        return \"Working: \" + str(proxyIP) + \":\" + str(proxyPort)\n",
    "      \n",
    "    except:\n",
    "        print(\"Proxy inactive: \" + str(proxyIP) + \":\" + str(proxyPort))\n",
    "        return \"Proxy inactive: \" + str(proxyIP) + \":\" + str(proxyPort)\n",
    "        driver.quit()\n",
    "    \n",
    "\n",
    "## Parallel read of soupParallel function\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import multiprocessing\n",
    "\n",
    "with parallel_backend('multiprocessing'):\n",
    "  num_cores = multiprocessing.cpu_count()\n",
    "  results = Parallel(n_jobs = num_cores)(delayed(proxySeleniumParallel)(proxyIP =list(proxies['IP Address'])[i], \n",
    "        proxyPort = list(proxies['Port'])[i], headless = True) for i in range(len(proxies.head(10)))) # len(proxies.head(10))\n",
    "\n",
    "print(pd.DataFrame(results))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HeadlessWebScraping_AMANV.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
